# NTU-Jetson-Gesture-CV-Project
# Gesture-Driven Response System on NVIDIA Jetson

**Real-time human gesture recognition â†’ automated text/audio response**

## ğŸš€ Project Overview

We build an end-to-end pipeline that:

1. Captures live camera frames on a Jetson  
2. Runs MediaPipe (or YOLO-Pose) for body/hand keypoints  
3. Feeds a 1D-Conv/LSTM classifier on sequences of keypoints  
4. Maps recognized gestures (â€œwaveâ€ / â€œdanceâ€) â†’ text or speech output  

---

## ğŸ—‚ï¸ Directory Structure

```text
â”œâ”€â”€ data/           # Raw gesture video clips (wave, dance)
â”œâ”€â”€ notebooks/      # EDA & preprocessing demos
â”œâ”€â”€ src/            # Main scripts and modules
â”œâ”€â”€ docs/           # Diagrams, reports
â”œâ”€â”€ environment.yml # Conda environment spec
â””â”€â”€ README.md       # Project overview & instructions
